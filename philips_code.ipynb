{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from maxvolpy.maxvol import rect_maxvol, maxvol\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it drop redundant features?\n",
    "\n",
    "$ 2 $ classes. We are generating a sample. Randomly choose one, then generate features for it. Different classes have different distributions of features. We generate $ n $ samples this way, suppose they all have $ k $ features. Replicate each column $ r $ times, so that we have $ n $ samples each with $ rk $ columns now. Add noise to each column.\n",
    "\n",
    "Invoke maxvol to select $ k $ columns. See how many duplicates it gets. The hypothesis we're checking is it selects very few duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(82138123)\n",
    "random.seed(82138123)\n",
    "\n",
    "k = 4\n",
    "\n",
    "# let all features of class 1 have mean -1\n",
    "# and let all features of class 2 have mean 1\n",
    "\n",
    "class_1_features_means = -1 * np.ones(k)\n",
    "class_2_features_means = np.ones(k)\n",
    "\n",
    "# now let's choose standard deviations for features\n",
    "# for each feature its standard deviation will be the same no matter class 1 or class 2\n",
    "min_feature_std = 0.5\n",
    "max_feature_std = 1.5\n",
    "features_stds = np.linspace(min_feature_variance, max_feature_variance, num=k)\n",
    "\n",
    "n = 1000\n",
    "class_1_prob = 0.75\n",
    "class_1_num_samples = np.random.binomial(n, class_1_prob)\n",
    "class_2_num_samples = n - class_1_num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's actually generate the data\n",
    "class_1_dataset = features_stds * np.random.randn(class_1_num_samples, k) + class_1_features_means\n",
    "class_2_dataset = features_stds * np.random.randn(class_2_num_samples, k) + class_2_features_means\n",
    "\n",
    "# num duplicates is r\n",
    "r = 5\n",
    "# build the whole dataset\n",
    "dataset = np.tile(\n",
    "    np.concatenate((class_1_dataset, class_2_dataset), axis=0),\n",
    "    r\n",
    ")\n",
    "# add noise\n",
    "noise_level = 0.1\n",
    "noise_std = noise_level * (min_feature_std + max_feature_std) / 2\n",
    "dataset += noise_std * np.random.randn(*dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for each $ i \\in \\{ 0, \\dots, \\text{ num_true_features} \\} $ correlation of each column with number $ i + j \\text{ num_true_features} $ is almost one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to choose the best 4-column submatrix using `rect_maxvol`.\n",
    "\n",
    "First let's try simply choosing 4 random rows.\n",
    "\n",
    "Then we'll first choosing good rows by `rect_maxvol`, then good columns by `rect_maxvol` on that.\n",
    "\n",
    "Then maybe try SVD truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_features(dataset, n, k, samples_choice):\n",
    "    if samples_choice == \"random\":\n",
    "        samples_subset_indices = np.random.choice(n, size=k, replace=False)\n",
    "    elif samples_choice == \"rect_maxvol\":\n",
    "        raise ValueError(\"Not implemented yet\")\n",
    "    else:\n",
    "        raise ValueError(\"Incorrect samples_choice parameter\")\n",
    "    features_subset_indices = rect_maxvol(dataset[samples_subset_indices, :].T, minK=k, maxK=k, tol=0.05)[0]\n",
    "    return features_subset_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_uniq_features(features_subset_indices):\n",
    "    return len(np.unique(features_subset_indices % k)) / len(features_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_features_indices = choose_features(dataset, n=n, k=k, samples_choice=\"random\")\n",
    "print(chosen_features_indices)\n",
    "print(chosen_features_indices % k)\n",
    "print(calculate_percentage_uniq_features(chosen_features_indices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
